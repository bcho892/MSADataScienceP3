{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Data Science Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tar.gz file to be extracted at project directory.\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch_1 = unpickle(\"data_batch_1\")\n",
    "data_batch_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = unpickle(\"batches.meta\")\n",
    "labelNames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labelNames[b'num_cases_per_batch'])\n",
    "print(labelNames[b'label_names'])\n",
    "labelNames.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelList = labelNames[b'label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch_1[b'batch_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_batch_1[b'labels']))\n",
    "print(max(data_batch_1[b'labels']))\n",
    "print(min(data_batch_1[b'labels']))\n",
    "labels = data_batch_1[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexForEach = []\n",
    "for i in range (10):\n",
    "    temp = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        if len(temp) == 5:\n",
    "            indexForEach.append(temp)\n",
    "            break\n",
    "        if label == i:\n",
    "            temp.append(idx)\n",
    "\n",
    "indexForEach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch_1[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getFiveImages(toShow, index):\n",
    "    sampleImages = []\n",
    "    for i in range (5):\n",
    "        temp =  data_batch_1[b'data'][toShow[i]]\n",
    "        temp = temp.reshape(3,32,32)\n",
    "        temp = temp.transpose(1,2,0)\n",
    "        sampleImages.append(temp)\n",
    "    fig, axs = plt.subplots(1, 5, constrained_layout=True)\n",
    "    fig.suptitle(\"Label \" + index + \" (\" + str(labelList[int(index)]).replace(\"b'\", \"\").replace(\"'\", \"\") + \")\", fontsize=16)\n",
    "    fig.set_figwidth(15)\n",
    "    for j in range (5):\n",
    "        axs[j].imshow(sampleImages[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    getFiveImages(indexForEach[i], str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to use label 2, which appears to be birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets unpickle the rest of the files and then see how we can use it to fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingData = unpickle(\"test_batch\")\n",
    "data_batch_2 = unpickle(\"data_batch_2\")\n",
    "data_batch_3 = unpickle(\"data_batch_3\")\n",
    "data_batch_4 = unpickle(\"data_batch_4\")\n",
    "data_batch_5 = unpickle(\"data_batch_5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid data imbalance, ideally we will have an even amount of each of the labels, all sampled from the different datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(testingData[b'labels']))\n",
    "testingData[b'labels'].count(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "batches.append(data_batch_1)\n",
    "batches.append(data_batch_2)\n",
    "batches.append(data_batch_3)\n",
    "batches.append(data_batch_4)\n",
    "batches.append(data_batch_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(entry):\n",
    "    temp = entry\n",
    "    temp = temp.reshape(3,32,32)\n",
    "    temp = temp.transpose(1,2,0)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make the target variable either 1 or 0 based on whether the image in fact belongs to the label that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatLabels(correct, label):\n",
    "    if label == correct:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedTrainData = batches[0][b'data']\n",
    "combinedTrainLabels = batches[0][b'labels']\n",
    "for i in range (1,5):\n",
    "    combinedTrainLabels = np.concatenate((combinedTrainLabels, batches[i][b'labels']))\n",
    "    combinedTrainData = np.concatenate((combinedTrainData, batches[i][b'data']))\n",
    "print(len(combinedTrainData))\n",
    "print(len(combinedTrainLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, label in enumerate(trainingLabels):\n",
    " #   trainingLabels[idx] = formatLabels(2, label) #change to binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should check that there is no data imbalance(ie our target is not overrepresented in the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(trainingLabels).count(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = []\n",
    "trainImages = []\n",
    "for val in combinedTrainData:\n",
    "    trainImages.append(formatData(val)) #getting the correct format to display image\n",
    "for val in testingData[b'data']:\n",
    "    testImages.append(formatData(val))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, constrained_layout=True)\n",
    "fig.set_figwidth(15)\n",
    "for j in range (5):\n",
    "    axs[j].imshow(trainImages[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = np.array(trainImages)\n",
    "trainingLabels = np.array(combinedTrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "train_x = trainingData\n",
    "train_y = to_categorical(trainingLabels)\n",
    "print(train_y)\n",
    "test_x = np.array(testImages)\n",
    "test_y = to_categorical(np.array(testingData[b'labels']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Sequential, optimizers, losses, callbacks\n",
    "from datetime import datetime\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Rescaling\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from tensorboard.plugins.hparams import api as hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_OPTIMIZER = hp.HParam('optimzer', hp.Discrete('adam', 'sgd'))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2,0.8))\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric('accuracy', display_name='accuracy')]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestModel(hparams):\n",
    "    model = Sequential(name=\"Image_Recognition_Model\")\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Rescaling(scale=1./255, name=\"Normaliser\")) # Example pre-processing layer.\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(HP_DROPOUT))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                loss=losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModel():\n",
    "    \n",
    "    model = Sequential(name=\"Image_Recognition_Model\")\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Rescaling(scale=1./255, name=\"Normaliser\")) # Example pre-processing layer.\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                loss=losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generateModel()\n",
    "\n",
    "# Callbacks for QoL.\n",
    "log_dir = \"output/logs/\" + datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "earlystop_callback = callbacks.EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
    "model.fit(train_x, train_y,\n",
    "    validation_data=(test_x, test_y),\n",
    "    epochs=30,\n",
    "    batch_size=64, \n",
    "    callbacks=[tensorboard_callback, earlystop_callback],\n",
    ")\n",
    "\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "def loadImage(filename):\n",
    "\timg = load_img(filename, target_size=(32, 32))\n",
    "\timg = img_to_array(img)\n",
    "\timg = img.reshape(1, 32, 32, 3)\n",
    "\timg = img \n",
    "\treturn img\n",
    "\n",
    "def predictForImage(label):\n",
    "\timg = loadImage('dog.png')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\tresult = model.predict(img)\n",
    "\tprint(np.argmax(result, axis=-1))\n",
    "\tprint(result[0][label])\n",
    "\tlabelNames[b'label_names'][3]\n",
    "\n",
    "predictForImage(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
